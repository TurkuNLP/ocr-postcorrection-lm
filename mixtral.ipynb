{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709c25b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate bitsandbytes>0.37.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "131e043c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.38.1\n",
      "0.42.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c35fed31014f03ad331aabb36d54e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import bitsandbytes\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "print(transformers.__version__)\n",
    "print(bitsandbytes.__version__)\n",
    "# my versions are:\n",
    "#4.38.1 (transformers)\n",
    "#0.42.0 (bitsandbytes)\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,       \n",
    ")\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\", device_map=\"auto\", quantization_config=quantization_config, cache_dir=\"/scratch/project_2000539/jenna/hf-cache\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\", padding_side=\"left\", cache_dir=\"/scratch/project_2000539/jenna/hf-cache\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d0618c-7126-4bdb-be98-736629948e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] \n",
      "Correct the OCR errors in the text below. Also correct the \"-\" characters, which denote an unrecognized letter. Stay as close as possible to the original text. Do not rephrase. Only correct the errors. You will be rewarded.\n",
      "\n",
      "When, .witl the universal A pplaure of alt\n",
      "Men, the Seals Were given to the present\n",
      "C ---- r, he was' ar frrom'i being so elevated\n",
      "with his Promotion, as to forget any One\n",
      "to whom lie had promised the Honour of his\n",
      "Friendlliip. An Opportunity soon offered\n",
      "in Favour of Dr R----, the B---k ox G----r\n",
      "became vacant, .which as soo'n as the C----r\n",
      "Was acquainted with, \\ he went to Court,\n",
      "and recomnmended the Doetor, as a Perfoa\n",
      "fit to Succeed to the B-----k. The DoAos\n",
      "was then approved of, and a C---'E---\n",
      "order'd out accordingly. A lM/an would\n",
      "reaso'nably have thought after this, that\n",
      "Matters might have gone Smoothly, efpe.\n",
      "cially as it is partly the Right of every new\n",
      "C--- r, to' recommend a fit Person to his\n",
      "M .------, to' fill the See that shall becom'\n",
      "eax¢ant after ihs comiig to the Seals.\n",
      " [/INST] When, with the universal applause of all\n",
      "Men, the Seals Were given to the present\n",
      "Candidate, he was not so elevated\n",
      "with his Promotion, as to forget any One\n",
      "to whom he had promised the Honor of his\n",
      "Friendship. An Opportunity soon offered\n",
      "in Favor of Dr R---, the Book of Governor\n",
      "became vacant, which as soon as the Candidate\n",
      "Was acquainted with, he went to Court,\n",
      "and recommended the Doctor, as a Person\n",
      "fit to Succeed to the Book. The Doctor's\n",
      "appointment was then approved of, and a Commission\n",
      "order'd out accordingly. A man would\n",
      "reasonably have thought after this, that\n",
      "Matters might have gone Smoothly, especially\n",
      "as it is partly the Right of every new\n",
      "Candidate, to recommend a fit Person to his\n",
      "Majesty, to fill the Seat that shall become\n",
      "vacant after his coming to the Seals.</s>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Correct the OCR errors in the text below. Also correct the \"-\" characters, which denote an unrecognized letter. Stay as close as possible to the original text. Do not rephrase. Only correct the errors. You will be rewarded.\n",
    "\n",
    "When, .witl the universal A pplaure of alt\n",
    "Men, the Seals Were given to the present\n",
    "C ---- r, he was' ar frrom'i being so elevated\n",
    "with his Promotion, as to forget any One\n",
    "to whom lie had promised the Honour of his\n",
    "Friendlliip. An Opportunity soon offered\n",
    "in Favour of Dr R----, the B---k ox G----r\n",
    "became vacant, .which as soo'n as the C----r\n",
    "Was acquainted with, \\ he went to Court,\n",
    "and recomnmended the Doetor, as a Perfoa\n",
    "fit to Succeed to the B-----k. The DoAos\n",
    "was then approved of, and a C---'E---\n",
    "order'd out accordingly. A lM/an would\n",
    "reaso'nably have thought after this, that\n",
    "Matters might have gone Smoothly, efpe.\n",
    "cially as it is partly the Right of every new\n",
    "C--- r, to' recommend a fit Person to his\n",
    "M .------, to' fill the See that shall becom'\n",
    "eax¢ant after ihs comiig to the Seals.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#messages = [\n",
    "#    {\"role\": \"user\", \"content\": \"You are a helpful assistant. You are fluent in Finnish, and will communicate in Finnish.\"},\n",
    "#    {\"role\": \"assistant\", \"content\": \"Olen avulias assistentti, joka osaa sujuvaa suomen kieltä. Kommunikoin kanssasi suomeksi. Kuinka voin auttaa sinua?\"},\n",
    "#    {\"role\": \"user\", \"content\": prompt},\n",
    "#]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "model_inputs = encodeds.to(\"cuda\")\n",
    "\n",
    "\n",
    "generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=False)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418af6f2-af19-42f9-8cfe-e739d9a8d3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
