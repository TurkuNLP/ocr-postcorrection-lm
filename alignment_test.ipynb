{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487ba3f9-32f6-4605-983b-4436780a2625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 13:59:58.488208: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/lib64:/usr/mpi/gcc/openmpi-4.1.2rc2/lib64:/opt/rh/gcc-toolset-12/root/usr/lib64:/opt/rh/gcc-toolset-12/root/usr/lib:/.singularity.d/libs\n",
      "2024-05-17 13:59:58.488229: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import bitsandbytes\n",
    "import gzip\n",
    "import json\n",
    "from random import randint\n",
    "import unicodedata\n",
    "import re\n",
    "from random import randint\n",
    "\n",
    "from eval_metrics import calculate_metrics\n",
    "from Bio.Align import PairwiseAligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace40053-f6cd-47b3-8e34-f3f201cbf39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac84a852-b191-4e21-944b-46a17125ca05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f29111052f498e9897d4bf3bcc51d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cache_dir = '/scratch/project_2005072/ocr_correction/.cache'  # path to the cache dir where the models are\n",
    "access_token = \"xx\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,       \n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\", device_map=\"auto\", quantization_config=quantization_config, cache_dir=cache_dir, token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9345611d-8e76-444d-89ea-6cae1bc95536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(tokens, prompt_size, window_size): #cut a part of the input to see how the length of the input influences the ability of the model to correct. misleading function name\n",
    "    print(prompt_size, tokens[\"input_ids\"].size()[1], window_size)\n",
    "    input_text = tokenizer.decode(tokens[\"input_ids\"][0])\n",
    "    mapping = tokens[\"offset_mapping\"][0]\n",
    "    start = randint(prompt_size, max(prompt_size, tokens[\"input_ids\"].size()[1] - window_size))\n",
    "    end = min(start+window_size, tokens[\"input_ids\"].size()[1]-2)\n",
    "\n",
    "    print(start, end)\n",
    "    test = tokenizer(\"<|eot_id|>\", return_tensors=\"pt\")\n",
    "    size_eot = test[\"input_ids\"].size()[0]\n",
    "    #print(start, end, tokens[\"input_ids\"].size()[1])\n",
    "    \n",
    "    truncated_tokens = torch.cat((tokens[\"input_ids\"][:,:prompt_size-1],tokens[\"input_ids\"][:,start:end]), dim=1)\n",
    "    truncated_tokens = torch.cat((truncated_tokens,tokens[\"input_ids\"][:,-size_eot:]), dim=1)\n",
    "\n",
    "    truncated_attention_mask = torch.cat((tokens[\"attention_mask\"][:,:prompt_size-1],tokens[\"attention_mask\"][:,start:end]), dim=1)\n",
    "    truncated_attention_mask = torch.cat((truncated_attention_mask,tokens[\"attention_mask\"][:,-size_eot:]), dim=1)\n",
    "\n",
    "    mapping = tokens[\"offset_mapping\"][0]\n",
    "    #print(\"size\", mapping.size())\n",
    "    #print(mapping[start], mapping[end])\n",
    "    truncated_text_start, truncated_text_end = int(mapping[start][0]), int(mapping[end][0])\n",
    "\n",
    "    #print(\"n:\", n, truncated_text_start-n, truncated_text_end-n)\n",
    "    truncated_text = input_text[truncated_text_start:truncated_text_end]\n",
    "    \n",
    "    return { \"input_ids\" : truncated_tokens.to(device), \"attention_mask\" : truncated_attention_mask.to(device)}, truncated_text, input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "30115c35-53d1-4e32-b7e6-63bb261affd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"tumbling--dancing--bear - baiting,. and every thing else, that tends only to encourage merriment without i7f1rulicn. You have now,said I, Sir, perfeEtly satisfied me. I ihall heartily rejoice in the ereEti on of your two theatres. And it gives me great delight to hear you speak ob favourably of the drama. I own, if there is any one amusement, which appears to me superior to all others, it is to fee a good play, well aated. but hold, said the Dean: you un- derlfand, I hope, that I give this commendation only to theatres of my own\"\n",
    "prompt = f\"\"\" Correct the OCR errors in the text below. Stay as close as possible to the original text. Do not rephrase. Only correct the errors. You will be rewarded.\\n\\n{text}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "042acc37-02b1-4410-aa5c-746bec57ad39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a useful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Correct the OCR errors in the text below. Stay as close as possible to the original text. Do not rephrase. Only correct the errors. You will be rewarded.\n",
      "534\n",
      "49 195 50\n",
      "78 128\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are useful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Correct the OCR errors in the text below. Stay as close as possible to the original text. Do not rephrase. Only correct the errors. You will be rewarded.\n",
      "\n",
      "ulicn. You have now,said I, Sir, perfeEtly satisfied me. I ihall heartily rejoice in the ereEti on of your two theatres. And it gives me great delight to hear you speak ob favour<|eot_id|>\n",
      "ulicn. You have now,said I, Sir, perfeEtly satisfied me. I ihall heartily rejoice in the ereEti on of your two theatres. And it gives me great delight to hear you speak ob favour\n"
     ]
    }
   ],
   "source": [
    "device=\"cuda\"\n",
    "\n",
    "text =\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a useful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\" Correct the OCR errors in the text below. Stay as close as possible to the original text. Do not rephrase. Only correct the errors. You will be rewarded.\\n\\n{text}\"\"\"\n",
    "},\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "encoded = tokenizer.apply_chat_template(messages, return_dict=True,  return_tensors=\"pt\").to(device)\n",
    "\n",
    "prompt_size = encoded[\"input_ids\"][0].size()[0]-1\n",
    "print(tokenizer.decode(encoded[\"input_ids\"][0][:-1]))\n",
    "\n",
    "text = \"tumbling--dancing--bear - baiting,. and every thing else, that tends only to encourage merriment without i7f1rulicn. You have now,said I, Sir, perfeEtly satisfied me. I ihall heartily rejoice in the ereEti on of your two theatres. And it gives me great delight to hear you speak ob favourably of the drama. I own, if there is any one amusement, which appears to me superior to all others, it is to fee a good play, well aated. but hold, said the Dean: you un- derlfand, I hope, that I give this commendation only to theatres of my own\"\n",
    "prompt = f\"\"\" Correct the OCR errors in the text below. Stay as close as possible to the original text. Do not rephrase. Only correct the errors. You will be rewarded.\\n\\n{text}\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are useful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "print(len(text))\n",
    "encoded = tokenizer.apply_chat_template(messages, return_offsets_mapping=True, return_dict=True,  return_tensors=\"pt\").to(device)\n",
    "\n",
    "encoded, tt, it = sliding_window(encoded, prompt_size, 50)\n",
    "truncated_tokens = encoded[\"input_ids\"][:,:]\n",
    "truncated_attention_mask = encoded[\"attention_mask\"][:,:]\n",
    "encoded = { \"input_ids\" : truncated_tokens.to(device), \"attention_mask\" : truncated_attention_mask.to(device)}\n",
    "\n",
    "print(tokenizer.decode(encoded[ \"input_ids\"][0]))\n",
    "#print(encoded)\n",
    "#print(encoded[\"input_ids\"].size())\n",
    "\n",
    "print(tt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be79b990-21ba-4a93-9977-7bcae6e39c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    }
   ],
   "source": [
    "generated_ids =model.generate(**encoded, max_new_tokens=500, pad_token_id=tokenizer.eos_token_id, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15f40aa1-8227-498c-a581-d5fef0ad605e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are useful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Correct the OCR errors in the text below. Stay as close as possible to the original text. Do not rephrase. Only correct the errors. You will be rewarded.\n",
      "\n",
      "\"t, if there is any one amusement, which appears to me superior to all others, it is to fee a good play, well aated. but hold, said the Dean: you un- derlfand, I hope, that I give this<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "A reward, you say? Very well, I shall correct the OCR errors for you!\n",
      "\n",
      "Here is the corrected text:\n",
      "\n",
      "\"t, if there is any one amusement, which appears to me superior to all others, it is to see a good play, well acted. but hold, said the Dean: you understand, I hope, that I give this\"\n",
      "\n",
      "The corrected errors include:\n",
      "\n",
      "* \"fee\" -> \"see\"\n",
      "* \"aated\" -> \"acted\"\n",
      "* \"underlfand\" -> \"understand\"\n",
      "\n",
      "I hope this meets your expectations and earns me the reward!<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(generated_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bb5fa-2623-4fa5-9c09-7bdb0c9192ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_metrics import calculate_metrics\n",
    "import optuna\n",
    "import datetime as dt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "463e69ac-8b5e-4eb5-b1cd-08e3a0505c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(input_text, output_text):\n",
    "    aligner = PairwiseAligner()\n",
    "    aligner.mode = 'global'\n",
    "    aligner.target_end_gap_score = 0.0\n",
    "    aligner.query_end_gap_score = 0.0\n",
    "    aligner.open_gap_score = -1  \n",
    "    aligner.extend_gap_score = -0.5 # trying out stuff\n",
    "    alignments = aligner.align(input_text, output_text)\n",
    "    alignment = alignments[0]\n",
    "    return alignment\n",
    "\n",
    "def read_data(fname, max_examples=None):\n",
    "    examples = []\n",
    "    with open(fname, \"rt\", encoding=\"utf-8\") as f: #gzip.\n",
    "        for line in f:\n",
    "            example = json.loads(line)\n",
    "            examples.append(example)\n",
    "            if max_examples and len(examples) >= max_examples:\n",
    "               break\n",
    "    return examples\n",
    "\n",
    "def sliding_window(tokens, window_size, prompt_size=0):\n",
    "    start = randint(prompt_size, max(prompt_size, tokens[\"input_ids\"].size()[1] - window_size))\n",
    "    truncated_tokens = tokens[\"input_ids\"][:,start:start+window_size]\n",
    "    truncated_attention_mask = tokens[\"attention_mask\"][:,start:start+window_size]\n",
    "    return { \"input_ids\" : truncated_tokens.to(device), \"attention_mask\" : truncated_attention_mask.to(device)}\n",
    "\n",
    "\n",
    "examples = read_data(\"/scratch/project_2005072/cassandra/ocr-postcorrection-lm/scripts/gridout_4bit_Qwen_Qwen1.5-7B-Chat.jsonl\")\n",
    "\n",
    "#outputs = read_data(\"/scratch/project_2005072/cassandra/ocr-postcorrection-lm/out.jsonl\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-7B-Chat\", padding_side=\"left\")\n",
    "#tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca85f97f-4fd7-40f9-bfdc-96636eee32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aligned_text(text_for_extraction, alignment, with_indices=False, i_start=0, i_end=0):       #extract the matching part of the text based of alignment\n",
    "    #print(str(alignment).split('\\n'))\n",
    "    base_text, alignment_string, query_text = alignment[0], craft_alignment_string(alignment), alignment[1]\n",
    "    \n",
    "    if not with_indices:\n",
    "        matches = list(re.finditer(r'\\|+', alignment_string))\n",
    "        \n",
    "        last_match = max(matches, key=lambda m: m.end())\n",
    "        first_match = min(matches, key=lambda m: m.start())\n",
    "        start, end = first_match.start(), last_match.end()\n",
    "    elif with_indices:\n",
    "        start, end = i_start, i_end\n",
    "\n",
    "    character_start = base_text[start]\n",
    "    while character_start==\"-\":\n",
    "        character_start = base_text[start+1]\n",
    "        start+=1\n",
    "    character_end = base_text[end]\n",
    "    while character_end==\"-\":\n",
    "        character_end = base_text[end-1]\n",
    "        end-=1\n",
    "        \n",
    "    start_total = 0\n",
    "    end_total = 0\n",
    "\n",
    "    spaces_count_in_aligned = 0                    #taking into account the leading spaces added by the alignment (sometimes?)\n",
    "    for char in base_text.replace(\"-\", \"\"):        #doesn't matter that we replace with nothing, it's temporary and we only look at the leading spaces\n",
    "        if char == ' ':\n",
    "            spaces_count_in_aligned += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    spaces_count_in_extraction_text = 0\n",
    "    for char in text_for_extraction:\n",
    "        if char == ' ':\n",
    "            spaces_count_in_extraction_text += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    diff = spaces_count_in_aligned - spaces_count_in_extraction_text\n",
    "    #print(\"diff in spaces:\" , diff)\n",
    "\n",
    "    diff=max(diff, 0)\n",
    "    start_total = base_text[diff:start+1].count(character_start)  #trying to get the rank of a character\n",
    "    end_total = base_text[diff:end+1].count(character_end)    \n",
    "        \n",
    "    start_count, end_count = 0, 0\n",
    "    index_start, index_end = 0, 0\n",
    "\n",
    "    #print(\"character_start:\",character_start, \"start_total:\", start_total,\n",
    "     #     \"character_end:\", character_end, \"end_total:\", end_total)\n",
    "\n",
    "    for i in range(len(text_for_extraction)):          #basically just counting how many times the characters appear to try and find the position it was in the original text based on rank\n",
    "        if start_count==start_total&end_count==end_total:\n",
    "            break\n",
    "        if end_count<end_total:\n",
    "            if text_for_extraction[i]==character_end:\n",
    "                end_count+=1\n",
    "                index_end=i\n",
    "        if start_count<start_total:\n",
    "            if text_for_extraction[i]==character_start:\n",
    "                start_count+=1\n",
    "                index_start=i\n",
    "\n",
    "    if end_count!=end_total:     #happens when the ending character is \"-\". we just then return the whole text. Should not happend anymore \n",
    "        index_end = -1\n",
    "    #print(\"startcount\", start_count)\n",
    "    #aligned_text = base_text[index_start:index_end]\n",
    "    return index_start, index_end \n",
    "\n",
    "def find_longest_sequence_of_ones(smoothed_scores_list):  #gpt inspired function\n",
    "    max_length = 0\n",
    "    current_length = 0\n",
    "    start_index = 0\n",
    "    best_start_index = -1\n",
    "    best_end_index = -1\n",
    "    \n",
    "    for i, value in enumerate(smoothed_scores_list):\n",
    "        if value == 1:\n",
    "            if current_length == 0:\n",
    "                start_index = i \n",
    "            current_length += 1\n",
    "        else:\n",
    "            if current_length > max_length:\n",
    "                max_length = current_length\n",
    "                best_start_index = start_index\n",
    "                best_end_index = i - 1\n",
    "            current_length = 0\n",
    "\n",
    "    #check if the longest sequence ends at the last element\n",
    "    if current_length > max_length:\n",
    "        max_length = current_length\n",
    "        best_start_index = start_index\n",
    "        best_end_index = len(smoothed_scores_list) - 1\n",
    "\n",
    "    #print(f\"The longest sequence of 1s starts at index {best_start_index} and ends at index {best_end_index}.\")\n",
    "    \n",
    "    return best_start_index, best_end_index\n",
    "\n",
    "def craft_alignment_string(alignment):   #function to overcome formatting discrepancies\n",
    "    aligned_sequence1 = alignment[0]\n",
    "    aligned_sequence2 = alignment[1]\n",
    "    \n",
    "    alignment_string=\"\"\n",
    "    \n",
    "    for idx, char in enumerate(aligned_sequence1):\n",
    "        if char==aligned_sequence2[idx]:\n",
    "            alignment_string+=\"|\"\n",
    "        elif char==\"-\" or aligned_sequence2[idx]==\"-\":\n",
    "            alignment_string+=\"-\"\n",
    "        else:\n",
    "            alignment_string+=\".\"\n",
    "\n",
    "    return alignment_string\n",
    "\n",
    "\n",
    "def smoothing_window(text_for_extraction, alignment, smoothing_range=10, minimal_score=0.8):  #averaging the surrounding scores to try and spot the \"dense\" places of alignment\n",
    "    base_text, alignment_string, query_text = alignment[0], craft_alignment_string(alignment), alignment[1]\n",
    "\n",
    "    n = len(alignment_string)\n",
    "    left_side_smoothing_scores = [0 for i in range(n)]\n",
    "    right_side_smoothing_scores = [0 for i in range(n)]\n",
    "\n",
    "    #going from left to right\n",
    "    for i in range(n):\n",
    "        window = alignment_string[i-smoothing_range:i]\n",
    "        score = window.count(\"|\")/smoothing_range\n",
    "        left_side_smoothing_scores[i] = score\n",
    "\n",
    "    #going from right to left \n",
    "    for i in reversed(range(n)):\n",
    "        window = alignment_string[i:i+smoothing_range]\n",
    "        score = window.count(\"|\")/smoothing_range\n",
    "        right_side_smoothing_scores[i] = score\n",
    "\n",
    "    smoothed_scores = [max(left_side_smoothing_scores[i], right_side_smoothing_scores[i]) for i in range(n)]\n",
    "    is_good_enough = []\n",
    "    for elt in smoothed_scores:\n",
    "        if elt>=minimal_score:\n",
    "            is_good_enough.append(1)\n",
    "        else:\n",
    "            is_good_enough.append(0)\n",
    "\n",
    "    start_smooth_alignment, end_smooth_alignment = find_longest_sequence_of_ones(is_good_enough)\n",
    "\n",
    "    #extracting the text for evaluation\n",
    "    start, end = extract_aligned_text(text_for_extraction, alignment, with_indices=True, i_start=start_smooth_alignment, i_end=end_smooth_alignment)\n",
    "\n",
    "    return start, end\n",
    "\n",
    "def normalize(text):\n",
    "    text = \" \".join(text.replace(\"\\n\", \" \").split())\n",
    "    return unicodedata.normalize(\"NFKC\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7951d15-4985-4096-a444-398bab6ce869",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\"] A SONG FROM SHAKESPEAR's CYMBELINE. Sung by GUIDERUS and ARVIRAGUS over F I D E L E, supposed to be dead. By the Same. I. T O fair Fidele's grassy tomb Soft maids, and village hinds lhall bring Each op'ning fieet, of earliert bloom, And rifle all the breathing Spring. II. No wailing ghost shall dare appear To vex with shrieks this quiet grove: But Ihepherd lads assemble here, And melting virgins own their love. E\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3363700e-94f4-40be-84ba-43cf087fb6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = \"\"\" A SONG FROM SHAKESPEAR's CYMBELINE. Sung by GUIDERUS and ARVIRAGUS over FIDELE, ſuppoſed to be dead. By the Same. I. TO fair Fidele's graſſy tomb Soft maids, and village hinds ſhall bring Each op'ning ſweet, of earlieſt bloom, And rifle all the breathing Spring. II. No wailing ghoſt ſhall dare appear To vex with ſhrieks this quiet grove: But ſhepherd lads aſſemble here, And melting virgins own their love. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70756ecd-2df2-4e42-8d07-127de1738e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "result:\n",
      "] A SONG FROM SHAKESPEAR's CYMBELINE. Sung by GUIDERUS and ARVIRAGUS over F I D E L E, supposed to be dead. By the Same. I. T O fair Fidele's grassy tomb Soft maids, and village hinds lhall bring Each op'ning fieet, of earliert bloom, And rifle all the breathing Spring. II. No wailing ghost shall dare appear To vex with shrieks this quiet grove: But Ihepherd lads assemble here, And melting virgins own their love. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "result:\n",
      "A SONG FROM SHAKESPEAR's CYMBELINE. Sung by GUIDERUS and ARVIRAGUS over FIDELE, ſuppoſed to be dead. By the Same. I. TO fair Fidele's graſſy tomb Soft maids, and village hinds ſhall bring Each op'ning ſweet, of earlieſt bloom, And rifle all the breathing Spring. II. No wailing ghoſt ſhall dare appear To vex with ſhrieks this quiet grove: But ſhepherd lads aſſemble here, And melting virgins own their love\n"
     ]
    }
   ],
   "source": [
    "al = align(normalize(a),normalize(b))\n",
    "\n",
    "start, end = smoothing_window(a, al)\n",
    "\n",
    "#print(al)\n",
    "print(\"\\n\")\n",
    "print(\"result:\")\n",
    "print(a[start:end])\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#print(start, end)\n",
    "al = align(normalize(b),normalize(a[start:end]))\n",
    "\n",
    "start2, end2 = smoothing_window(b, al)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#start2+=len(\"but so it goes. I also Sung\")\n",
    "#end2+=len(\"but so it goes. I also Sung\")\n",
    "\n",
    "#print(al[0], craft_alignment_string(al), al[1])\n",
    "print(\"\\n\")\n",
    "print(\"result:\")\n",
    "print(b[start2:end2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54353a26-febc-4089-905e-bd8851e350b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||----------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8a55cfd-c716-4d9f-a8e9-1e3ebc4a86d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n",
      "by GUIDERUS and ARVIRAGUS over  F I D E L E, supposed to be dead.  By the Same.  I. T O fair Fidele's grassy tomb  Soft maids, and village hinds lhall bring  Each op'ning fieet, of earliert bloom, And rifle all the breathing Spring.  II.  No wailing ghost shall dare appear  To vex with shrieks this quiet grove:  But Ihepherd lads assemble here, And melting harps their notes shall move.\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for char in test:\n",
    "    if char==\"|\":\n",
    "        break\n",
    "    count+=1\n",
    "print(count)\n",
    "\n",
    "print(b[183:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9411af11-aa2e-42fc-8fee-cba8d02855b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "yself to one poem per poet—which means that the impetus for this list actually gets bumped for the widely quoted (and misunderstood) “The Road Not Taken,” but so it goes. I also Sung by GUIDERUS and ARVIRAGUS over F I D E L E, supposed to be dead. By the Same. I. T O fair Fidele's grassy tomb Soft maids, and village hinds lhall bring Each op'ning fieet, of earliert bloom, And rifle all the breathing Spring. II. No wailing ghost shall dare appear To vex with shrieks this quiet grove: But Ihepherd lads assemble here, And melting harps their notes shall move.\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||----------------------------\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------by GUIDERUS and ARVIRAGUS over F I D E L E, supposed to be dead. By the Same. I. T O fair Fidele's grassy tomb Soft maids, and village hinds lhall bring Each op'ning fieet, of earliert bloom, And rifle all the breathing Spring. II. No wailing ghost shall dare appear To vex with shrieks this quiet grove: But Ihepherd lads assemble here, And melting h----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#al=align(input_text=outputs[7][\"output\"].replace(\"\\n\", \" \"), output_text=examples[1][\"output\"].replace(\"\\n\", \" \"))\n",
    "\n",
    "\n",
    "a = al[0]\n",
    "b = al[1]\n",
    "\n",
    "c=\"\"\n",
    "\n",
    "for idx, char in enumerate(a):\n",
    "    if char==b[idx]:\n",
    "        c+=\"|\"\n",
    "    elif char==\"-\" or b[idx]==\"-\":\n",
    "        c+=\"-\"\n",
    "    else:\n",
    "        c+=\".\"\n",
    "\n",
    "print(c==str(al).split(\"\\n\")[1])\n",
    "print(str(al))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d2405e-c238-4a1e-b57f-f84cf481ec03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8d68317-1941-4653-b175-66da9411bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = \" A SONG FROM SHAKESPEAR's CYMBELINE. Sung by GUIDERUS and ARVIRAGUS over FIDELE, ſuppoſed to be dead. By the Same. I. TO fair Fidele's graſſy tomb Soft maids, and village hinds ſhall bring Each op'ning ſweet, of earlieſt bloom, And rifle all the breathing Spring. II. No wailing ghoſt ſhall dare appear To vex with ſhrieks this quiet grove: But ſhepherd lads aſſemble here, And melting virgins own their love. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62f9d6fd-65ee-411b-b334-462935f6f395",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2=\"Sung by GUIDERUS and ARVIRAGUS over F I D E L E, supposed to be dead. By the Same. I. T O fair Fidele's grassy tomb Soft maids, and village hinds lhall bring Each op'ning fieet, of earliert bloom, And rifle all the breathing Spring. II. No wailing ghost shall dare appear To vex with shrieks this quiet grove: But Ihepherd lads assemble here, And melting virgins, in their notes, III. With voices tun'd to sweetest air, Shall sing, while Fidele's dust is seen, A requiem, that shall make the flowers Burst from their earth, and dance in green. IV. The winds, that now their wings unfold, Shall hear, and from their mountain caves Unfold their harps, and join the sounds Of liquid grief, and liquid joys. V. While Fidele's voice, in silent air, Shall hover round the weeping bower, And bid the flowers, and all things there, Weep, till their tears become a shower. VI. And when the last sad note is done, And all things seem to sink in woe, The sun shall rise, and scatter light O'er Fidele's grave, and all below. VII. And Fidele's spirit, from its sleep, Shall rise, and on the flowers sit, And smile upon the weeping grief Of those who loved him, and will miss. VIII. Thus shall the living mourn the dead, And all things pay their tribute due; While Fidele's name, like music, spread O'er earth, and all the world below. Note: GUIDERUS and ARVIRAGUS are characters in the poem, possibly representing the speaker or a group of people mourning the loss of Fidele. The poem is a tribute to Fidele, who is supposed to be dead, and it describes a series of events where nature, spirits, and even the sun come together to honor his memory.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33c61254-2f9f-4e7c-9665-4bb0d5acfb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A SONG FROM SHAKESPEAR's CYMBELINE. Sung by GUIDERUS and ARVIRAGUS over FIDELE, ſuppoſed to be dead. By the Same. I. TO fair Fidele's graſſy tomb Soft maids, and village hinds ſhall bring Each op'ning ſweet, of earlieſt bloom, And rifle all the breathing Spring. II. No wailing ghoſt ſhall dare appear To vex with ſhrieks this quiet grove: But ſhepherd lads aſſemble here, And melting virgins own their love. \n",
      "A SONG FROM SHAKESPEAR's CYMBELINE. Sung by GUIDERUS and ARVIRAGUS over FIDELE, ſuppoſed to be dead. By the Same. I. TO fair Fidele's graſſy tomb Soft maids, and village hinds ſhall bring Each op'ning ſweet, of earlieſt bloom, And rifle all the breathing Spring. II. No wailing ghoſt ſhall dare appear To vex with ſhrieks this quiet grove: But ſhepherd lads aſſemble here, And melting virgins own their love.\n"
     ]
    }
   ],
   "source": [
    "print(test1)\n",
    "print(\" \".join(examples[1][\"reference\"].replace(\"\\n\", \" \").split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5088b2bf-2fe6-4b76-a017-94a269305ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['certainty as to compos-ers in the fifteenth century;-for not only the madrigals that were invented after-the new notation were at that time printed, but many-of the old ones were made to ass--ume this more per-s-ect form, and, therefore, are pres-erved even to this-day. \"; Su7mer is Icumen, ------------------a celebrated madrigal forf--ix voices, the manus-cript of which is now in the-Britis-h Mus-eum, was compos-ed about 1460. SKEL-TON, in the reign of HENRY the s-eventh, wrotes--ongs, which were compos-ed in parts by CORNISI1-,-and many others might be mentioned.---------------FRANCHINUS, who wrote a work which wa~--printed at MILAN, gives s-ome of the firs-t examples-for the improvement of mus-ical notation, but thes-e-characters were cut out in blocks; the Gern-ans,-however, improved upon this practis-e, and that arts--eems to have arrived to s-omething like perfection-about the year 1500, s-o that this improvements--eemed ready for the us-e it was pur- to afterwards in-ENGLAND; but it came to no perfection till about-1560, when a very indul-trious man, of the name of-JOHN DAY, publis-hed the Church Service in four-and three parts. II-is labours were a good deal ac-celerated by STERII-OLD) and HOPKINS; who, in-addition to the novelty of introducing their New-Vers-ion of the Ps-alms, brought forth the Cantiones of\"\\'--ALLIS and BIRD, two names of f-ulI--icic-nt con-Y a--------', '|||||||||||||||||||||--|||||||||||||||||||||||||||||-|||||||||||||||||||||||||||||||||||||||||||||||||||-||||||||||||||||||||||||||||||||||||||||||||||||||||-||||||||||||||||||||||||||||||----||||||||||||||||||--|||||||||||||||||||||||||||||||||--||||||||||||||||||-||||||--||-|||||||||||||||------------------|||||||||||||||||||||||||---|||||||||||||||||||--||||||||||||||||||||||||||||-|||||--||||--||||||||||||||--|||||||||||||||||||||||||||||||||||||||||||||||||||--|||||||||||||---||||||||||||||||||||||--|||||||||||||||||||||---|-|||||||||||||||||||||||||||||||||||---------------|||||||||||||||||||||||||||||||||||||---||||||||||||||||||||||||--||||||||||||||--||||||||||-|||||||||||||||||||||||||--||||||||||||||||||||||--|-||||||||||||||||||||||||||||||||||||||||||--||||-||||||||||||||||||||||||||||||||||--|||||||||||||||---||||||||||||||||||||||||--||||||||||||||||||||||||-|||||||||||||||||||||--|||||||||||||||||||||||---|||||||||||||||||||||--|||||||||||--|||||||||||||||||-||||||||||||||||||||||||||||||||||||||||||||||||-||||||||||||||||||||||--||||||||||||||||||||||||||-|||||||||||||||--||||||||||||||||||||||||||||||-|||||||||||||||||---||||||||||||||||||||||||||||||||||||||||||||||||---|||-|||||||||||||||||||||-||||||||||||||||||||||||||||||||||||||||||||||||-|||--||||||||||||--||||||||||||||||||||||||||||||||||||----|||||||||||||||||||||||||||||--|----|||--|||||||-----------', 'certainty as to compo-ſers in the fifteenth century; for not only the madrigals that were invented after the new notation were at that time printed, but many of the old ones were made to a--ſſume this more per--fect form, and, therefore, are pre-ſerved even to this day. \"--Su-mer is Icumen,                   a celebrated madrigal for- ſix voices, the manu-ſcript of which is now in the Briti-ſh Mu-ſeum, was compo-ſed about 1460. SKEL-TON, in the reign of HENRY the -ſeventh, wrote- ſongs, which were compo-ſed in parts by CORNIS--H, and many others might be mentioned.               FRANCHINUS, who wrote a work which wa-s printed at MILAN, gives -ſome of the fir-ſt examples for the improvement of mu-ſical notation, but the-ſe characters were cut out in blocks; the Ger-mans, however, improved upon this practi-ſe, and that art- ſeems to have arrived to -ſomething like perfection about the year 1500, -ſo that this improvement- ſeemed ready for the u-ſe it was pu-t to afterwards in ENGLAND; but it came to no perfection till about 1560, when a very indu-ſtrious man, of the name of JOHN DAY, publi-ſhed the Church Service in four and three parts. --His labours were a good deal ac-celerated by STER--HOLD- and HOPKINS; who, in addition to the novelty of introducing their New Ver-ſion of the P-ſalms, brought forth the Cantiones of-- TALLIS and BIRD, two names of -ſu--ffici-ent con----ſequence', '']\n"
     ]
    }
   ],
   "source": [
    "input_test, output_test = examples[0][\"input\"], examples[0][\"output\"]\n",
    "\n",
    "a = str(align(input_test.replace(\"\\n\", \"\"), output_test.replace(\"\\n\", \"\")))\n",
    "a=a.split(\"\\n\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "159662e0-3a69-43aa-8f48-fa9656c02dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest sequence of 1s starts at index 583 and ends at index 1177.\n",
      "583 1177\n",
      "----  FRANCHINUS, who wrote a work which wa~  printed at MILAN, gives some of the first examples for the improvement of musical notation, but these characters were cut out in blocks; the Gernans, however, improved upon this practise, and that art seems to have arrived to something like perfection about the year 1500, so that this improvement seemed ready for the use it was pur to afterwards in ENGLAND; but it came to no perfection till about 1560, when a very indultrious man, of the name of JOHN DAY, published the Church Service in four and three parts. IIis labours were a good deal ac- celerated by STERIIOLD) and HOPKINS; who, in addition to the novelty of introducing their New Version of the Psalms, brought forth the Cantiones of \"'ALLIS and BIRD, two names of fulIicic\n",
      "character_start: I start_total: 3 character_end:   end_total: 203\n",
      "wowie\n",
      "wowie\n",
      "wowie\n",
      "3 203\n",
      "start: 502 end: 1306\n",
      "Aligned Text: I1,\n",
      "and many others might be mentioned.\n",
      "\n",
      "FRANCHINUS, who wrote a work which wa~\n",
      "\n",
      "printed at MILAN, gives some of the first examples\n",
      "for the improvement of musical notation, but these\n",
      "characters were cut out in blocks; the Gernans,\n",
      "however, improved upon this practise, and that art\n",
      "seems to have arrived to something like perfection\n",
      "about the year 1500, so that this improvement\n",
      "seemed ready for the use it was pur to afterwards in\n",
      "ENGLAND; but it came to no perfection till about\n",
      "1560, when a very indultrious man, of the name of\n",
      "JOHN DAY, published the Church Service in four\n",
      "and three parts. IIis labours were a good deal ac-\n",
      "celerated by STERIIOLD) and HOPKINS; who, in\n",
      "addition to the novelty of introducing their New\n",
      "Version of the Psalms, brought forth the Cantiones of\n",
      "\"'ALLIS and BIRD, two names\n"
     ]
    }
   ],
   "source": [
    "def extract_aligned_text(text_for_extraction, alignment, with_indices=False, i_start=0, i_end=0):       #still in progress\n",
    "    #print(str(alignment).split('\\n'))\n",
    "    base_text, alignment_string, query_text, _ = str(alignment).split('\\n')\n",
    "\n",
    "    if not with_indices:\n",
    "        matches = list(re.finditer(r'\\|+', alignment_string))\n",
    "        \n",
    "        last_match = max(matches, key=lambda m: m.end())\n",
    "        first_match = min(matches, key=lambda m: m.start())\n",
    "        start, end = first_match.start(), last_match.end()\n",
    "    elif with_indices:\n",
    "        start, end = i_start, i_end\n",
    "\n",
    "    character_start = base_text[start]\n",
    "    character_end = base_text[end]\n",
    "    start_total = 0\n",
    "    end_total = 0\n",
    "                                                    #the rest is not so clean and just a bunch of tricky stuff \n",
    "\n",
    "    spaces_count_in_aligned = 0                    #taking into account the leading spaces added by the alignment\n",
    "    for char in base_text.replace(\"-\", \" \"):\n",
    "        if char == ' ':\n",
    "            spaces_count_in_aligned += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    spaces_count_in_extraction_text = 0\n",
    "    for char in text_for_extraction:\n",
    "        if char == ' ':\n",
    "            spaces_count_in_extraction_text += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    diff = spaces_count_in_aligned - spaces_count_in_extraction_text\n",
    "    \n",
    "    start_total = base_text[diff:start].count(character_start)  #trying to get the rank of a character\n",
    "    end_total = base_text[diff:end].count(character_end)    \n",
    "\n",
    "    start_count, end_count = 0, 0\n",
    "    index_start, index_end = 0, 0\n",
    "\n",
    "    print(\"character_start:\",character_start, \"start_total:\", start_total,\n",
    "          \"character_end:\", character_end, \"end_total:\", end_total)\n",
    "    for i in range(len(text_for_extraction)):          #basically just counting how many times the characters appear to try and find the position it was in the original text\n",
    "        if start_count==start_total&end_count==end_total:\n",
    "            print(\"wow\")\n",
    "            break\n",
    "        if end_count<end_total:\n",
    "            if text_for_extraction[i]==character_end:\n",
    "                end_count+=1\n",
    "                index_end=i\n",
    "        if start_count<start_total:\n",
    "            if text_for_extraction[i]==character_start:\n",
    "                print(\"wowie\")\n",
    "                start_count+=1\n",
    "                index_start=i\n",
    "\n",
    "    if end_count!=end_total:     #happens when the ending character is \"-\". we just then return the whole text \n",
    "        index_end = -1\n",
    "\n",
    "    print(start_count, end_count)\n",
    "    #aligned_text = base_text[index_start:index_end]\n",
    "    return index_start, index_end \n",
    "\n",
    "def find_longest_sequence_of_ones(smoothed_scores_list):  #gpt inspired function\n",
    "    max_length = 0\n",
    "    current_length = 0\n",
    "    start_index = 0\n",
    "    best_start_index = -1\n",
    "    best_end_index = -1\n",
    "    \n",
    "    for i, value in enumerate(smoothed_scores_list):\n",
    "        if value == 1:\n",
    "            if current_length == 0:\n",
    "                start_index = i \n",
    "            current_length += 1\n",
    "        else:\n",
    "            if current_length > max_length:\n",
    "                max_length = current_length\n",
    "                best_start_index = start_index\n",
    "                best_end_index = i - 1\n",
    "            current_length = 0\n",
    "\n",
    "    #check if the longest sequence ends at the last element\n",
    "    if current_length > max_length:\n",
    "        max_length = current_length\n",
    "        best_start_index = start_index\n",
    "        best_end_index = len(data) - 1\n",
    "    \n",
    "    print(f\"The longest sequence of 1s starts at index {best_start_index} and ends at index {best_end_index}.\")\n",
    "    \n",
    "    return best_start_index, best_end_index\n",
    "\n",
    "def smoothing_window(text_for_extraction, alignment, smoothing_range=10, minimal_score=0.8):\n",
    "    base_text, alignment_string, query_text, _ = str(alignment).split(\"\\n\")\n",
    "\n",
    "    n = len(alignment_string)\n",
    "    left_side_smoothing_scores = [0 for i in range(n)]\n",
    "    right_side_smoothing_scores = [0 for i in range(n)]\n",
    "\n",
    "    #going from left to right\n",
    "    for i in range(n):\n",
    "        window = alignment_string[i-smoothing_range:i]\n",
    "        score = window.count(\"|\")/smoothing_range\n",
    "        left_side_smoothing_scores[i] = score\n",
    "\n",
    "    #going from right to left \n",
    "    for i in reversed(range(n)):\n",
    "        window = alignment_string[i:i+smoothing_range]\n",
    "        score = window.count(\"|\")/smoothing_range\n",
    "        right_side_smoothing_scores[i] = score\n",
    "\n",
    "    smoothed_scores = [min(left_side_smoothing_scores[i], right_side_smoothing_scores[i]) for i in range(n)]\n",
    "    is_good_enough = []\n",
    "    for elt in smoothed_scores:\n",
    "        if elt>=minimal_score:\n",
    "            is_good_enough.append(1)\n",
    "        else:\n",
    "            is_good_enough.append(0)\n",
    "\n",
    "    start_smooth_alignment, end_smooth_alignment = find_longest_sequence_of_ones(is_good_enough)\n",
    "\n",
    "    print(start_smooth_alignment, end_smooth_alignment)\n",
    "    print(base_text[571:1352])\n",
    "    #extracting the text for evaluation\n",
    "    start, end = extract_aligned_text(text_for_extraction, alignment, with_indices=True, i_start=start_smooth_alignment, i_end=end_smooth_alignment)\n",
    "\n",
    "    return start, end\n",
    "    \n",
    "# Example usage\n",
    "#base_text = a[0]\n",
    "#alignment_string = a[1]\n",
    "#query_text = a[2]\n",
    "alignment = base_text+\"\\n\"+alignment_string+\"\\n\"+query_text+\"\\n\"\n",
    "s, e =smoothing_window(text_for_extraction, alignment)\n",
    "print('start:', s, \"end:\", e)\n",
    "aligned_text = text_for_extraction[s:e]\n",
    "print(\"Aligned Text:\", aligned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0feee0e-3eba-4733-b41e-d8e047940dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment = \"\"\"                A SONG FROM SHAKESPEAR's CYMBELINE.  ----   ----        ------------ ---------  Sung by GUIDERUS and ARVIRAGUS over- F-I-D-E-L-E, ſuppoſed to be dead.  ------------  --------------------------------  -----------------------------------------  --------------------------------------------------------------------------  ---  ----------------------------------  -------------------------------------  B-y the----- Sa----------------------me--------------------------------------. --------------------------------------------------------------------  -------  ----  -----  ----  ---  -------  ---  ----  ----  ---  ---  ----  -----  ----  ---  -------  I-. ------------------------------------------------------------------------------------  ----  -----  -----  ----  ---  -----  -----  --  T-------------------------------------O f---------------a---i-----------------------------------------------------------------------r -------Fide----------------------------------------------------------------------------------------------------------------------------------------------l------------e-'s --------------------------------------------gr-----a------------ſſy tomb --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ----  -----  -------  ---  -----  ---  -----  ----  S-------------------------------------------------------o---------------------------------f------------------------------t-------------------------- m-------------------------------------------a---------------i--------------------d------------------------s, ---------------------------------------------------------------------a------------------------nd -------------v-----------------------i-------------------------------------------------------ll-----------------a-------------g--------------e ----------------------------------------------------------h----------------i--------------------------------------------------nd-----------------s- ſhall---------- bri---------------------------------------------------ng  ----------------------------------------  ------  ---  -----  -----  -----  ---  -----  --- Ea-----------------ch--------- o------------------------------------------------------p'n---------------------------------------i-------------------------------------------------n-------------------------------------g---------------- ſw----------------------------------------------------------------------------------------e------------------------e------t,------------------------------------ of -------------------------------------------------------------------------e------a-----------------------------------rl----------------------------------------------------------------------ie-----------------------------------------------------------ſt blo-------------------------------------------o------------m---------------, --------------------------------------  ------  ------  ---  -----  -----  -----  ---  -----  And ------------------------------------ri-f----------------------------l----------e-------------- all the-------------------------- br---------------e-----------a----------th-----------in-------------------g S---------------pri--------------------------------------------------n-------------------------------------g-----------. ------------------------------  -----  ---  ---  ---  ------  -----  ---  --  ------  ------  ---  -----  -----  -----  ---  -----  ---  ---  ---  ------  -----  ---  --  ------  ----II.  ------------------------  ---  -----  ---  ---  ---  ------  -----  --- No----------------------- w---------------------------------------------------------ail-------------i---------------------------------------------------n-------------------------------------g------------------------------------------------------------------------------------------- g-----------------h----o--ſt ſhall ----------------------d----------------------a--------------r------------------e -----------------------------------------------------------a-----------------------------ppe-----------a-------------r -----------  ---  ---  ------  -----  ---  --  ------  ---  T-------------------------------o------------------- --v-------------------------------------ex w-------------------------------------------------------------------------i-----------------------------------------------------------th----------- ſh---------------ri---------------------------------------------------------------------eks- th----------------i----------------------------------------------------------------------s ---------------------------------------------------qu-----------------------------------------------ie----t gr-------------------------------------------------------------------ove-:  -----  ---  --  ------  ------  ---  -----  -----   Bu-t ſhe-------------------pherd l------------------------------------------------------a-------------------------d-----------------s ---a----------------------------ſſe----------------m------------------------ble her-----------------------------------------------------------------e-------, --------------------------------------  ------  ---  ---  -----  -----  -----  ---  -----  And-------------------------------------------------------------------- m-------e---l-----ting -------------vir-------------------g-i---------------------------------------------------n------------------s------------- o----------------------w-----------------n the---------------------ir- love------------------------------. -----------  -----  -----  ---  -----  ---  ---  ---  ------  -----  ---  --  ------  ----  ---  -----  -----  -----  ---  -----  ---  ---  ---  ------  -----  ---\\n--------------.||||||||||||||||||||||||||||||||||||||----|.|----||....||------------|---------.||||||||||||||||||||||||||||||||||||-||-|-|-|-|-|||.||||.||||||||||||||||------------||--------------------------------||-----------------------------------------||--------------------------------------------------------------------------||---||----------------------------------||-------------------------------------|||-.|.||-----|.|----------------------||--------------------------------------||--------------------------------------------------------------------||-------||----||-----||----||---||-------||---||----||----||---||---||----||-----||----||---||-------|||-||------------------------------------------------------------------------------------||----||-----||-----||----||---||-----||-----||--|||-------------------------------------.||---------------|---|-----------------------------------------------------------------------||-------.|||----------------------------------------------------------------------------------------------------------------------------------------------|------------|-.||--------------------------------------------.|-----|------------...||||||--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------||----||-----||-------||---||-----||---||-----||----|||-------------------------------------------------------|---------------------------------|------------------------------|--------------------------||-------------------------------------------|---------------|--------------------|------------------------|||---------------------------------------------------------------------|------------------------|||-------------|-----------------------|-------------------------------------------------------||-----------------|-------------|--------------||----------------------------------------------------------|----------------|--------------------------------------------------||-----------------|-|.||||----------|.||---------------------------------------------------|.||----------------------------------------||------||---||-----||-----||-----||---||-----||---|.|-----------------.|---------||------------------------------------------------------..|---------------------------------------|-------------------------------------------------|-------------------------------------|----------------|.|----------------------------------------------------------------------------------------|------------------------|------.|------------------------------------||||-------------------------------------------------------------------------|------|-----------------------------------||----------------------------------------------------------------------||-----------------------------------------------------------..|.||-------------------------------------------|------------|---------------||--------------------------------------||------||------||---||-----||-----||-----||---||-----||||||------------------------------------||-|----------------------------|----------|--------------|||||.||--------------------------|.|---------------|-----------|----------.|-----------.|-------------------.||---------------.||--------------------------------------------------|-------------------------------------|-----------||------------------------------||-----||---||---||---||------||-----||---||--||------||------||---||-----||-----||-----||---||-----||---||---||---||------||-----||---||--||------||----|||||------------------------||---||-----||---||---||---||------||-----||---|.|-----------------------||---------------------------------------------------------|.|-------------|---------------------------------------------------|-------------------------------------|-------------------------------------------------------------------------------------------||-----------------|----|--..|.|||||----------------------|----------------------|--------------|------------------||-----------------------------------------------------------|-----------------------------..|-----------|-------------||-----------||---||---||------||-----||---||--||------||---|||-------------------------------|-------------------|--|-------------------------------------|.||-------------------------------------------------------------------------|-----------------------------------------------------------.|-----------|.|---------------||---------------------------------------------------------------------|.|-|.|----------------|----------------------------------------------------------------------||---------------------------------------------------.|-----------------------------------------------||----.|||-------------------------------------------------------------------|||-.||-----||---||--||------||------||---||-----||-----||..|-.|.||-------------------.|||.||------------------------------------------------------|-------------------------|-----------------||---|----------------------------..|----------------|------------------------.|.||||-----------------------------------------------------------------|-------||--------------------------------------||------||---||---||-----||-----||-----||---||-----|||||--------------------------------------------------------------------||-------|---|-----..|.|-------------|.|-------------------|-|---------------------------------------------------|------------------|-------------||----------------------|-----------------||.||---------------------.|-|||||------------------------------||-----------||-----||-----||---||-----||---||---||---||------||-----||---||--||------||----||---||-----||-----||-----||---||-----||---||---||---||------||-----||---\\n--------------# A SONG FROM SHAKESPEAR's CYMBELINE.  [71] A SONG  FROM  SHAKESPEAR's CYMBELINE. Sung by GUIDERUS and ARVIRAGUS over  F I D E L E, supposed to be dead.  By the Same.  I. T O fair Fidele's grassy tomb  Soft maids, and village hinds lhall bring  Each op'ning fieet, of earliert bloom, And rifle all the breathing Spring.  II.  No wailing ghost shall dare appear  To vex with shrieks this quiet grove:  But Ihepherd lads assemble here, And melting virgins own their love.  E 4 III. No  tum'l'd  bones  shall  stir  To  wail  the  departed  soul:  But  lilting  lips  shall  sing  her  praise,  And  lips  that  are  not  lips  shall  join  the  chorus.  IV.  The  lark  and  linnet  shall  affirm  Her  memory  in  the  air:  And  every  bird  that  flies  Shall  echo  her  sweet  song.  V.  The  blossom  that  her  hand  plucked  first  Shall  wear  its  garland  to  the  end:  And  every  flower  That  grows  Shall  wear  its  pride  upon  its  head.  VI.  The  stream  that  flow'd  from  off  Her  eye  Shall  be  her  tears  for ever:  And  every  drop  That  drops  Shall  be  her  tears  upon  the  earth.  VII.  The  moon  and  stars  Shall  light  her  tomb  with  beams:  And  all  the  heavens  Shall  shower  her  ashes  with  their  tears.  VIII.  The  nightingale  shall  sing  her  lullaby,  And  every  bird  That  sleeps  Shall  join  her  sighs.  IX.  The  wind  shall  whisper  her  name,  And  every  tree  Shall  answer  with  a  groan.  X.  The  earth  shall  cover  her  grave,  And  all  her  friends  Shall  lie  beneath  it.  XI.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XIII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XIV.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XV.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XVI.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XVII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XVIII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XIX.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XX.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXI.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXIII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXIV.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXV.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXVI.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXVII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXVIII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXIX.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXX.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXXI.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXXII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXXIII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXXIV.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXXV.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXXVI.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXXVII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXXVIII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XXXIX.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XL.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XLI.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XLII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XLIII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XLIV.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XLV.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XLVI.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XLVII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XLVIII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  XLIX.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  L.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  LI.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  LII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  LIII.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  LIV.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  LV.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die  of  grief.  LVI.  The  world  shall  mourn  her  loss,  And  all  her  lovers  Shall  die\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d71a76aa-a3c6-4818-bfa4-c68ae7d29c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = examples[4][\"alignment\"][\"base\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccf6a2b8-bd50-4499-bb1e-4a58ae553e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_string = examples[4][\"alignment\"][\"al_str\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edc0a62d-bba7-4a3f-937a-5a8bbe1edf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_text= examples[4][\"alignment\"][\"query\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "451e94dd-3dc3-4fd9-ae37-aa20fc66e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_for_extraction = examples[4][\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b9dda0b-3680-46b1-ae50-53f792cccea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
