{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "832ac838-63a7-4e98-b5ae-d3fde3908da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import gzip\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b38aa9c8-01c9-4f87-bae3-dddfc2f0f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start ollama server and activate venv\n",
    "!bash ../alignment-and-gridsearch/scripts/start_ollama.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "367bfd4d-3f3d-4d5f-a959-fabae68fc7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_sets = {\n",
    "    \"fr\" : \"/scratch/project_2005072/cassandra/ocr-postcorrection-data/French/ICDAR2017/fr_test_doc.jsonl.gz\", \n",
    "    \"fi\" : \"/scratch/project_2005072/cassandra/ocr-postcorrection-data/Finnish/fin_test_abbyy_old_doc.jsonl.gz\", \n",
    "    \"en\" : \"/scratch/project_2005072/cassandra/ocr-postcorrection-data/English/FULL_DOCUMENTS/en_test_full.jsonl.gz\", \n",
    "    \"JohnDoe\" : \"/scratch/project_2005072/cassandra/ocr-postcorrection-lm/trashbin/smol_sample.jsonl.gz\"\n",
    "}\n",
    "\n",
    "\n",
    "# Reference Post-It of models and quantizations\n",
    "\n",
    "ollama_models = {\n",
    "    \"meta-llama/Meta-Llama-3-8B-Instruct\" : \"llama3:8b-instruct\",\n",
    "    \"meta-llama/Meta-Llama-3.1-8B-Instruct\" : \"llama3.1:8b-instruct\",\n",
    "    \"meta-llama/Meta-Llama-3.1-70B-Instruct\" : \"llama3.1:70b-instruct\",\n",
    "    \"google/gemma-7b-it\" : \"gemma:7b-instruct\",\n",
    "    \"google/gemma-2-9b-it\" : \"gemma2:9b-instruct\", \n",
    "    \"google/gemma-2-27b-it\" : \"gemma2:27b-instruct\", \n",
    "    \"mistralai/Mixtral-8x7B-Instruct-v0.1\" : \"mixtral:8x7b-instruct-v0.1\"\n",
    "}\n",
    "\n",
    "quantization_levels = [\"-fp32\", \"-fp16\", \n",
    "                       \"-q4_0\", \"-q4_1\", \n",
    "                       \"-q5_0\", \"-q5_1\", \n",
    "                       \"-q2_K\", \n",
    "                       \"-q3_K\", \"-q3_K_M\", \"-q3_K_S\", \"-q3_K_L\",\n",
    "                       \"-q4_K\", \"-q4_K_M\", \"-q4_K_S\", \n",
    "                       \"-q5_K\", \"-q5_K_M\", \"-q5_K_S\", \n",
    "                       \"-q6_K\", \n",
    "                       \"-q8_0\"]   # not all versions of every model have been downloaded. use ollama pull <model>:<tags> to get one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a997600f-f662-4c8a-b3c1-427d3085cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up your custom parameters for \n",
    "\n",
    "#temperature = 0.2\n",
    "#mirostat = 2\n",
    "#mirostat_tau = 4\n",
    "#window_size = 300\n",
    "#overlap_percentage = 0.4\n",
    "#open_gap_score = -0.5\n",
    "#extend_gap_score = -1.5\n",
    "\n",
    "language = \"JohnDoe\"\n",
    "input_file = evaluation_sets[language]\n",
    "\n",
    "quantization = \"-q5_K_M\"\n",
    "\n",
    "models_to_evaluate = [\"meta-llama/Meta-Llama-3.1-8B-Instruct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df770e50-0fab-4567-9c27-73cafd9611dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-25 15:50:19.866633: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/lib64:/usr/mpi/gcc/openmpi-4.1.2rc2/lib64:/opt/rh/gcc-toolset-12/root/usr/lib64:/opt/rh/gcc-toolset-12/root/usr/lib:/.singularity.d/libs\n",
      "2024-09-25 15:50:19.866656: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "usage: produce_correction.py [-h] [--output_file OUTPUT_FILE]\n",
      "                             [--input_file INPUT_FILE] [--model MODEL]\n",
      "                             [--quantization QUANTIZATION]\n",
      "                             [--window_size WINDOW_SIZE]\n",
      "                             [--temperature TEMPERATURE]\n",
      "                             [--overlap_percentage OVERLAP_PERCENTAGE]\n",
      "                             [--mirostat MIROSTAT]\n",
      "                             [--mirostat_tau MIROSTAT_TAU]\n",
      "                             [--open_gap_score OPEN_GAP_SCORE]\n",
      "                             [--extend_gap_score EXTEND_GAP_SCORE]\n",
      "                             [--pp_degree PP_DEGREE]\n",
      "produce_correction.py: error: argument --input_file: expected one argument\n"
     ]
    }
   ],
   "source": [
    "# this will run the model to correct the input file with the selected parameters and will produce an outputfile in ../alignment-and-gridsearch/output_evaluation/\n",
    "!python ../alignment-and-gridsearch/produce_correction.py \\\n",
    "--input_file {input_file} \\\n",
    "--model {model} \\\n",
    "--quantization {quantization}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e48e91d8-86c9-4da0-bd2b-d491d6d2d9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ollama\n",
      "  Downloading ollama-0.3.3-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.9/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.6)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.4)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.9/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /usr/local/lib/python3.9/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (4.10.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.9/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.0)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.3.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe771d5-e8cc-415c-8a0e-2f6975a5410e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
